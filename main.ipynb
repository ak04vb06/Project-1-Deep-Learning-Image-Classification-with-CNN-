{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642ab947",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80ce06cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          image_path label\n",
      "0  C:\\Users\\rache\\Downloads\\archive\\raw-img\\cane\\...   dog\n",
      "1  C:\\Users\\rache\\Downloads\\archive\\raw-img\\cane\\...   dog\n",
      "2  C:\\Users\\rache\\Downloads\\archive\\raw-img\\cane\\...   dog\n",
      "3  C:\\Users\\rache\\Downloads\\archive\\raw-img\\cane\\...   dog\n",
      "4  C:\\Users\\rache\\Downloads\\archive\\raw-img\\cane\\...   dog\n",
      "Total images: 26179\n",
      "label\n",
      "dog          4863\n",
      "ragno        4821\n",
      "chicken      3098\n",
      "horse        2623\n",
      "butterfly    2112\n",
      "cow          1866\n",
      "squirrel     1862\n",
      "sheep        1820\n",
      "cat          1668\n",
      "elephant     1446\n",
      "Name: count, dtype: int64\n",
      "Train size: 23561\n",
      "Test size: 2618\n",
      "Image batch shape: (32, 224, 224, 3)\n",
      "Label batch shape: (32,)\n",
      "Example labels: [3 7 5 2 6 7 2 7 0 7]\n",
      "Min pixel: 0.0\n",
      "Max pixel: 1.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from translate import translate\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "\n",
    "# -----------------------------\n",
    "# 1️⃣ Build DataFrame with translated labels\n",
    "# -----------------------------\n",
    "dataset_path = r\"C:\\Users\\rache\\Downloads\\archive\\raw-img\"\n",
    "data = []\n",
    "\n",
    "# Iterate through each folder in the dataset directory\n",
    "for folder in os.listdir(dataset_path):\n",
    "    folder_path = os.path.join(dataset_path, folder)\n",
    "\n",
    "    # Check if the current path is actually a directory\n",
    "    if os.path.isdir(folder_path):\n",
    "        # Get the label from the 'translate' dict, or default to folder name\n",
    "        label = translate.get(folder, folder)\n",
    "\n",
    "        # Iterate through files inside the category folder\n",
    "        for file in os.listdir(folder_path):\n",
    "            # Filter specifically for image formats\n",
    "            if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                img_path = os.path.join(folder_path, file)\n",
    "                # Store the full path and its corresponding label\n",
    "                data.append([img_path, label])\n",
    "\n",
    "# Create a Pandas DataFrame to manage metadata\n",
    "df = pd.DataFrame(data, columns=[\"image_path\", \"label\"])\n",
    "\n",
    "# Display the first few rows and distribution stats\n",
    "print(df.head())\n",
    "print(\"Total images:\", len(df))\n",
    "print(df['label'].value_counts())\n",
    "\n",
    "# -----------------------------\n",
    "# 2️⃣ Train / Test Split (90/10)\n",
    "# -----------------------------\n",
    "train_df, test_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.1,\n",
    "    stratify=df['label'],\n",
    "    random_state=42\n",
    ")\n",
    "print(\"Train size:\", len(train_df))\n",
    "print(\"Test size:\", len(test_df))\n",
    "\n",
    "# -----------------------------\n",
    "# 3️⃣ Function to convert DataFrame to tf.data.Dataset\n",
    "# -----------------------------\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "def df_to_dataset(df, shuffle=True, batch_size=32):\n",
    "    # Extract file paths and convert labels from strings to integer codes\n",
    "    paths = df['image_path'].values\n",
    "    labels = df['label'].astype('category').cat.codes.values  # string -> integer\n",
    "\n",
    "    # Create a basic TensorSliceDataset\n",
    "    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "\n",
    "    # Internal function to load and preprocess images\n",
    "    def process_path(path, label):\n",
    "        # Read the raw file from disk\n",
    "        img = tf.io.read_file(path)\n",
    "        # Decode the JPEG format into a tensor (0-255 integers)\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        # Resize image to the input size required by the model (224x224)\n",
    "        img = tf.image.resize(img, [IMG_SIZE, IMG_SIZE])\n",
    "        # Normalize pixel values to range [0, 1] (crucial for convergence)\n",
    "        img = img / 255.0\n",
    "        return img, label\n",
    "\n",
    "    # Apply the processing function in parallel using available CPU cores\n",
    "    ds = ds.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    # Shuffle the dataset to prevent the model from learning order-based patterns\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(df))\n",
    "\n",
    "    # Group examples into batches\n",
    "    ds = ds.batch(batch_size)\n",
    "    # Prefetch data to GPU memory while CPU prepares the next batch (pipeline optimization)\n",
    "    ds = ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "    return ds\n",
    "\n",
    "# -----------------------------\n",
    "# 4️⃣ Create TensorFlow Datasets\n",
    "# -----------------------------\n",
    "train_dataset = df_to_dataset(train_df, batch_size=BATCH_SIZE)   # shuffled for training\n",
    "test_dataset = df_to_dataset(test_df, shuffle=False, batch_size=BATCH_SIZE)  # no shuffle for testing\n",
    "\n",
    "# -----------------------------\n",
    "# 5️⃣ Quick verification\n",
    "# -----------------------------\n",
    "for images, labels in train_dataset.take(1):\n",
    "    print(\"Image batch shape:\", images.shape)\n",
    "    print(\"Label batch shape:\", labels.shape)\n",
    "    print(\"Example labels:\", labels[:10].numpy())\n",
    "    print(\"Min pixel:\", images.numpy().min())\n",
    "    print(\"Max pixel:\", images.numpy().max())\n",
    "\n",
    "# Visualize the first image\n",
    "img = images[0].numpy()\n",
    "Image.fromarray((img * 255).astype(\"uint8\")).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd170a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rache\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">55,392</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m96\u001b[0m)     │        \u001b[38;5;34m55,392\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m96\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m6,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">81,642</span> (318.91 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m81,642\u001b[0m (318.91 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">81,642</span> (318.91 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m81,642\u001b[0m (318.91 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m737/737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 278ms/step - accuracy: 0.2270 - loss: 2.1247 - val_accuracy: 0.2865 - val_loss: 1.9676\n",
      "Epoch 2/15\n",
      "\u001b[1m737/737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 276ms/step - accuracy: 0.3201 - loss: 1.9146 - val_accuracy: 0.3594 - val_loss: 1.7681\n",
      "Epoch 3/15\n",
      "\u001b[1m737/737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 273ms/step - accuracy: 0.3751 - loss: 1.7755 - val_accuracy: 0.4335 - val_loss: 1.6070\n",
      "Epoch 4/15\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# -----------------------------\n",
    "# 1️⃣ Déterminer le nombre de classes\n",
    "# -----------------------------\n",
    "num_classes = len(df['label'].unique())\n",
    "print(\"Number of classes:\", num_classes)\n",
    "\n",
    "# -----------------------------\n",
    "# 2️⃣ Définir le CNN from scratch\n",
    "# -----------------------------\n",
    "model = tf.keras.Sequential([\n",
    "\n",
    "    layers.Conv2D(32, 3, activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "    layers.MaxPooling2D(),\n",
    "\n",
    "    layers.Conv2D(64, 3, activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "\n",
    "    layers.Conv2D(96, 3, activation='relu'),   # au lieu de 128\n",
    "    layers.MaxPooling2D(),\n",
    "\n",
    "    layers.GlobalAveragePooling2D(),  # remplace Flatten (énorme diff)\n",
    "\n",
    "    layers.Dense(64, activation='relu'),  # au lieu de 128\n",
    "    layers.Dropout(0.4),\n",
    "\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 3️⃣ Compiler le modèle\n",
    "# -----------------------------\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# -----------------------------\n",
    "# 4️⃣ Entraîner le modèle\n",
    "# -----------------------------\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=test_dataset,\n",
    "    epochs=15   # tu peux augmenter si tu as le temps et le GPU\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 5️⃣ Tester / visualiser quelques prédictions\n",
    "# -----------------------------\n",
    "# Mapping entier -> label\n",
    "label_mapping = dict(enumerate(df['label'].astype('category').cat.categories))\n",
    "\n",
    "# Prédire sur un batch de test\n",
    "for images, labels in test_dataset.take(1):\n",
    "    preds = model.predict(images)\n",
    "    pred_classes = np.argmax(preds, axis=1)\n",
    "\n",
    "    for i in range(len(images)):\n",
    "        img = images[i].numpy()\n",
    "        Image.fromarray((img*255).astype(\"uint8\")).show(title=label_mapping[pred_classes[i]])\n",
    "        print(\"Predicted:\", label_mapping[pred_classes[i]], \"| Actual:\", label_mapping[labels[i].numpy()])\n",
    "        # done \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "946228b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available: 0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))\n",
    "print(tf.config.list_physical_devices('GPU'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
