{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b51839ce",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d6338f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1ï¸ CONFIGURATION ET DATAFRAME (InchangÃ© ou presque)\n",
    "# ---------------------------------------------------------\n",
    "dataset_path = r\"C:\\Users\\rache\\Downloads\\archive\\raw-img\"\n",
    "translate = {\"cane\": \"dog\", \"cavallo\": \"horse\", \"elefante\": \"elephant\", \"farfalla\": \"butterfly\", \n",
    "             \"gallina\": \"chicken\", \"gatto\": \"cat\", \"mucca\": \"cow\", \"pecora\": \"sheep\", \n",
    "             \"scoiattolo\": \"squirrel\", \"ragno\": \"ragno\"}\n",
    "\n",
    "data = []\n",
    "for folder in os.listdir(dataset_path):\n",
    "    folder_path = os.path.join(dataset_path, folder)\n",
    "    if os.path.isdir(folder_path):\n",
    "        label = translate.get(folder, folder)\n",
    "        for file in os.listdir(folder_path):\n",
    "            if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                data.append([os.path.join(folder_path, file), label])\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"image_path\", \"label\"])\n",
    "num_classes = len(df['label'].unique())\n",
    "label_mapping = dict(enumerate(df['label'].astype('category').cat.categories))\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.1, stratify=df['label'], random_state=42)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1.5ï¸ CLASSES ET TRANSFORMS (Obligatoire pour que Ã§a tourne)\n",
    "# ---------------------------------------------------------\n",
    "class AnimalDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        # On convertit les noms (dog, cat...) en chiffres (0, 1...)\n",
    "        self.label_to_idx = {v: k for k, v in label_mapping.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.iloc[idx, 0]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        label = self.label_to_idx[self.df.iloc[idx, 1]]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Initialisation de l'historique pour les graphiques\n",
    "history = {'loss': [], 'accuracy': []}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 2ï¸ DATA LOADING (AjustÃ© : Batch Size = 32)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "BATCH_SIZE = 32 # ModifiÃ© selon ton tableau\n",
    "\n",
    "train_loader = DataLoader(AnimalDataset(train_df, transform), batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(AnimalDataset(test_df, transform), batch_size=BATCH_SIZE)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# 3ï¸ MODÃˆLE 2 (Avec Dropout pour rÃ©duire l'overfitting)\n",
    "# ---------------------------------------------------------\n",
    "class AnimalCNN_V2(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(64, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 28 * 28, 64),\n",
    "            nn.ReLU(),\n",
    "            # --- LA MODIFICATION EST ICI ---\n",
    "            nn.Dropout(0.5), # On dÃ©sactive 50% des connexions alÃ©atoirement\n",
    "            # -------------------------------\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return self.classifier(x)\n",
    "\n",
    "# N'oublie pas de recrÃ©er le modÃ¨le et l'optimizer\n",
    "\n",
    "# 1. DÃ©finir le moteur (GPU ou CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 2. CrÃ©er l'objet du modÃ¨le ET l'envoyer sur la carte direct\n",
    "model = AnimalCNN_V2(num_classes=num_classes).to(device)\n",
    "\n",
    "# 3. CrÃ©er l'optimiseur (il va maintenant lier les paramÃ¨tres qui sont dÃ©jÃ  sur le GPU)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 4. DÃ©finir la fonction de perte\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4ï¸ ENTRAÃŽNEMENT (ParamÃ¨tres Model 1)\n",
    "# ---------------------------------------------------------\n",
    "# Optimizer: Adam | Learning rate: default (0.001) | Momentum: No\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Epochs: 15 (comme spÃ©cifiÃ©)\n",
    "\n",
    "\n",
    "for epoch in range(15):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        # Transfert vers la 5070\n",
    "        images, labels = images.to(device), labels.to(device, dtype=torch.long)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss/len(train_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    history['loss'].append(epoch_loss)\n",
    "    history['accuracy'].append(epoch_acc)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/15 | Loss: {epoch_loss:.4f} | Acc: {epoch_acc:.2f}%\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# 5ï¸ VALIDATION LOOP (The \"Real\" Test)\n",
    "# ---------------------------------------------------------\n",
    "model.eval()  # Switch to evaluation mode (turns off Dropout)\n",
    "val_correct = 0\n",
    "val_total = 0\n",
    "\n",
    "print(\"\\nðŸ” Running Validation on unseen images...\")\n",
    "\n",
    "with torch.no_grad(): # Disable gradient calculation (saves memory/time)\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        val_total += labels.size(0)\n",
    "        val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "val_accuracy = 100 * val_correct / val_total\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 6 VISUALISATION (Remplace tes plots matplotlib)\n",
    "# ---------------------------------------------------------\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Loss')\n",
    "plt.plot(history['loss'], color='blue')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Accuracy')\n",
    "plt.plot(history['accuracy'], color='green')\n",
    "print(f\"âœ… Final Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "plt.savefig('resultats_model_2.png')\n",
    "plt.show()\n",
    "\n",
    "print(\"ITS DONE ! ðŸŽ‰\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155a6f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# 7 VISUALISATION DES PRÃ‰DICTIONS (Test sur 10 images)\n",
    "# ---------------------------------------------------------\n",
    "def visualize_predictions(model, test_loader, num_images=10):\n",
    "    model.eval()\n",
    "    images_shown = 0\n",
    "    plt.figure(figsize=(15, 6)) # Taille de la fenÃªtre d'affichage\n",
    "\n",
    "    # On rÃ©cupÃ¨re le nom des classes dans l'ordre\n",
    "    class_names = [label_mapping[i] for i in range(len(label_mapping))]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for i in range(images.size(0)):\n",
    "                if images_shown >= num_images:\n",
    "                    break\n",
    "                \n",
    "                # PrÃ©paration de l'image pour l'affichage (on doit la remettre en format standard)\n",
    "                img = images[i].cpu().numpy().transpose((1, 2, 0))\n",
    "                mean = np.array([0.485, 0.456, 0.406])\n",
    "                std = np.array([0.229, 0.224, 0.225])\n",
    "                img = std * img + mean # DÃ©normalisation\n",
    "                img = np.clip(img, 0, 1)\n",
    "\n",
    "                ax = plt.subplot(2, 5, images_shown + 1)\n",
    "                plt.imshow(img)\n",
    "                \n",
    "                # Couleur du texte : Vert si c'est bon, Rouge si c'est faux\n",
    "                color = 'green' if preds[i] == labels[i] else 'red'\n",
    "                \n",
    "                plt.title(f\"P: {class_names[preds[i].item()]}\\n(V: {class_names[labels[i].item()]})\", \n",
    "                          color=color, fontsize=10)\n",
    "                plt.axis('off')\n",
    "                images_shown += 1\n",
    "            \n",
    "            if images_shown >= num_images:\n",
    "                break\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Appeler la fonction\n",
    "visualize_predictions(model, test_loader, num_images=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
